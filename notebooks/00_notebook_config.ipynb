{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Configuration of experiments \n",
    "\n",
    "This notebook demonstrates the usage of the Config class from the qedft library to manage and manipulate configuration settings for experiments. It covers the following steps:\n",
    "1. Initialization of a Config object.\n",
    "2. Setting specific configuration parameters.\n",
    "3. Retrieving and displaying configuration parameters.\n",
    "4. Loading configuration settings from a YAML file.\n",
    "5. Saving the current configuration to a JSON file.\n",
    "6. Reloading configuration settings from the JSON file.\n",
    "7. Outputting the entire current configuration to the console.\n",
    "8. Simulating command line argument input for configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import qedft\n",
    "from qedft.config.config import Config, setup_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured number of qubits: 4\n",
      "Configured batch size: 32\n",
      "Current configuration settings:\n",
      "{'name': 'test_vase', 'experiment_name': 'test', 'network_type': 'mlp', 'molecule_name': 'h2', 'molecule_names': ['h2', 'h4'], 'dataset': [42, 384], 'dataset1': [128, 384], 'dataset2': [160, 240], 'rng': 0, 'save_plot_loss': False, 'save_every_n': 42, 'activation': 'tanh', 'n_neurons': 42, 'n_layers': 42, 'n_qubits': 42, 'n_reupload_layers': 42, 'use_rzz_parametrized_entanglers': False, 'chebychev_reuploading': False, 'add_reversed_rzz': False, 'entangling_block_type': 'circular', 'single_qubit_rotations': ['rx', 'rz', 'rx'], 'use_same_parameters': False, 'add_negative_transform': False, 'wrap_with_self_interaction_layer': False, 'wrap_with_global_functional': False, 'use_correlators_in_output': False, 'output_operators': ['Z'], 'use_bias_in_output': False, 'max_train_steps': 42, 'factr': 1.0, 'pgtol': 1e-14, 'm': 42, 'maxfun': 20, 'maxiter': 2, 'num_iterations': 20, 'ks_iter_to_ignore': 10, 'discount_factor': 0.9, 'alpha': 0.5, 'alpha_decay': 0.9, 'num_mixing_iterations': 1, 'density_mse_converge_tolerance': -1.0, 'stop_gradient_step': -1, 'enforce_reflection_symmetry': False, 'use_relative_encoding': False, 'num_grids': 42, 'use_amplitude_encoding': False, 'max_number_conv_layers': 100, 'list_qubits_per_layer': [], 'force_qubits_per_layer_is_kernel_width': False, 'feature_map_type': 'direct', 'final_mlp_layers': [1], 'dont_use_parametrized_observables': True, 'use_nel_as_input_with_mlp': False, 'nel_exc_combination_type': 'sum', 'nel_mlp_layers': [1], 'density_normalization_factor': 2.0, 'use_pmap_for_gpu_per_molecule': False, 'num_global_filters': 16, 'num_local_filters': 16, 'num_local_conv_layers': 2, 'ksr_activation': 'swish', 'ksr_minval': 0.1, 'ksr_maxval': 2.385345, 'ksr_downsample_factor': 0, 'use_exponential_coulomb': True, 'jit_loss': True, 'jit_neural_xc': True, 'model': {'quantum': {'n_qubits': 4}}, 'training': {'batch_size': 32}, 'discount': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a configuration object to manage our settings\n",
    "config = Config()\n",
    "\n",
    "# Define specific configuration parameters\n",
    "# The dot notation allows us to set and get configuration parameters in a hierarchical manner\n",
    "config.set('model.quantum.n_qubits', 4)  # Set the number of qubits for the quantum model\n",
    "config.set('training.batch_size', 32)    # Set the batch size for training\n",
    "\n",
    "# Retrieve and display the configuration parameters\n",
    "n_qubits = config.get('model.quantum.n_qubits')\n",
    "batch_size = config.get('training.batch_size')\n",
    "\n",
    "print(f\"Configured number of qubits: {n_qubits}\")\n",
    "print(f\"Configured batch size: {batch_size}\")\n",
    "\n",
    "# Define the project path, assuming 'settings.yaml' is located in the root directory\n",
    "project_path = Path(os.path.dirname(os.path.dirname(qedft.__file__)))\n",
    "\n",
    "# Load configuration settings from a YAML file\n",
    "config.load_from_yaml(project_path / 'tests' / 'test_files' / 'custom_config.yaml')\n",
    "\n",
    "# Persist the current configuration to a JSON file for future reference\n",
    "config.save_to_json(project_path / 'tests' / 'test_files' / 'custom_config.json')\n",
    "\n",
    "# Reload configuration settings from the JSON file to ensure consistency\n",
    "config.load_from_json(project_path / 'tests' / 'test_files' / 'custom_config.json')\n",
    "\n",
    "# Output the entire current configuration to the console\n",
    "print(\"Current configuration settings:\")\n",
    "print(config.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration with command line arguments applied:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'test',\n",
       " 'experiment_name': 'test',\n",
       " 'network_type': 'ksr',\n",
       " 'molecule_name': 'h2',\n",
       " 'molecule_names': ['h2', 'h4'],\n",
       " 'dataset': [128, 384],\n",
       " 'dataset1': [128, 384],\n",
       " 'dataset2': [160, 240],\n",
       " 'rng': 0,\n",
       " 'save_plot_loss': False,\n",
       " 'save_every_n': 20,\n",
       " 'activation': 'tanh',\n",
       " 'n_neurons': 32,\n",
       " 'n_layers': 42,\n",
       " 'n_qubits': 42,\n",
       " 'n_reupload_layers': 1,\n",
       " 'use_rzz_parametrized_entanglers': False,\n",
       " 'chebychev_reuploading': False,\n",
       " 'add_reversed_rzz': False,\n",
       " 'entangling_block_type': 'alternate_linear',\n",
       " 'single_qubit_rotations': ['rz', 'rx', 'rz'],\n",
       " 'use_same_parameters': False,\n",
       " 'add_negative_transform': False,\n",
       " 'wrap_with_self_interaction_layer': False,\n",
       " 'wrap_with_global_functional': False,\n",
       " 'use_correlators_in_output': False,\n",
       " 'output_operators': ['Z'],\n",
       " 'use_bias_in_output': False,\n",
       " 'max_train_steps': 10000,\n",
       " 'factr': 1.0,\n",
       " 'pgtol': 1e-14,\n",
       " 'm': 20,\n",
       " 'maxfun': 20,\n",
       " 'maxiter': 2,\n",
       " 'num_iterations': 15,\n",
       " 'ks_iter_to_ignore': 10,\n",
       " 'discount_factor': 0.9,\n",
       " 'alpha': 0.5,\n",
       " 'alpha_decay': 0.9,\n",
       " 'num_mixing_iterations': 1,\n",
       " 'density_mse_converge_tolerance': -1.0,\n",
       " 'stop_gradient_step': -1,\n",
       " 'enforce_reflection_symmetry': False,\n",
       " 'use_relative_encoding': False,\n",
       " 'num_grids': 513,\n",
       " 'use_amplitude_encoding': False,\n",
       " 'max_number_conv_layers': 100,\n",
       " 'list_qubits_per_layer': [],\n",
       " 'force_qubits_per_layer_is_kernel_width': False,\n",
       " 'feature_map_type': 'direct',\n",
       " 'final_mlp_layers': [1],\n",
       " 'dont_use_parametrized_observables': True,\n",
       " 'use_nel_as_input_with_mlp': False,\n",
       " 'nel_exc_combination_type': 'sum',\n",
       " 'nel_mlp_layers': [1],\n",
       " 'density_normalization_factor': 2.0,\n",
       " 'use_pmap_for_gpu_per_molecule': False,\n",
       " 'num_global_filters': 16,\n",
       " 'num_local_filters': 16,\n",
       " 'num_local_conv_layers': 2,\n",
       " 'ksr_activation': 'swish',\n",
       " 'ksr_minval': 0.1,\n",
       " 'ksr_maxval': 2.385345,\n",
       " 'ksr_downsample_factor': 0,\n",
       " 'use_exponential_coulomb': True,\n",
       " 'jit_loss': True,\n",
       " 'jit_neural_xc': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate command line argument input for configuration\n",
    "sys.argv = [\n",
    "    \"notebook\",\n",
    "    \"--n_qubits\", \"42\",\n",
    "    \"--n_layers\", \"42\"\n",
    "]\n",
    "\n",
    "# Setup configuration using command line arguments and display the updated settings\n",
    "config_with_args = setup_config()\n",
    "\n",
    "print(\"\\nConfiguration with command line arguments applied:\")\n",
    "config_with_args.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, we demonstrated the usage of the configuration management system in our project. We covered:\n",
    "\n",
    "- Creating and initializing a Config object\n",
    "- Setting configuration parameters using dot notation\n",
    "- Loading configuration from YAML and JSON files\n",
    "- Saving configuration to JSON files\n",
    "- Retrieving configuration values\n",
    "- Handling command line arguments for configuration\n",
    "\n",
    "This configuration system provides a flexible and maintainable way to manage settings across our project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qedft-V5mY4H-k-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
