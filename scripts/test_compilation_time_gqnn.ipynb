{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63fbf2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-25 13:57:25.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-25 13:57:25.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-25 13:57:25.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-25 13:57:25.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n",
      "[-8.46313258]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import qedft\n",
    "from qedft.models.networks import GlobalQiCQNN, GlobalQiQNN, GlobalQNN\n",
    "from qedft.config.config import Config\n",
    "from qedft.train.od.trainer import KSDFTTrainer\n",
    "from horqrux.utils.operator_utils import DiffMode\n",
    "from loguru import logger\n",
    "\n",
    "# Set the default dtype as float64\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# set gpu device\n",
    "jax.config.update(\"jax_platform_name\", \"cuda\")  # \"cuda\" or \"cpu\"\n",
    "\n",
    "# Get project path\n",
    "project_path = Path(os.path.dirname(os.path.dirname(qedft.__file__)))\n",
    "\n",
    "# Load base configuration\n",
    "config = Config(config_path=project_path / 'qedft' / 'config' / 'train_config.yaml').config\n",
    "\n",
    "# Let's change to settings to have a global functional\n",
    "config['network_type'] = 'conv_dqc'\n",
    "config['use_amplitude_encoding'] = True\n",
    "\n",
    "# Configure GlobalQNN\n",
    "qicnn_config = {\n",
    "    \"network_type\": \"conv_dqc\",\n",
    "    \"wrap_self_interaction\": False,\n",
    "    \"wrap_with_negative_transform\": False,\n",
    "    \"use_amplitude_encoding\": True,\n",
    "    \"n_qubits\": 6,  # Number of qubits in the quantum layer\n",
    "    \"n_var_layers\": 4,  # Number of quantum layers\n",
    "    \"n_layers\": 4,\n",
    "    \"largest_kernel_width\": 3,\n",
    "    \"max_number_conv_layers\": 1,  # Limit to 1 convolutional layer\n",
    "    \"list_qubits_per_layer\": [],\n",
    "    \"force_qubits_per_layer_is_kernel_width\": False,\n",
    "    \"normalization\": 1.0,\n",
    "    \"last_layer_type\": \"dense\",  # Use a linear layer at the end\n",
    "    \"use_bias_mlp\": False,\n",
    "    \"last_layer_features\": [1],\n",
    "    \"diff_mode\": DiffMode.AD,\n",
    "    \"n_shots\": 0,\n",
    "    \"key\": jax.random.PRNGKey(0)\n",
    "}\n",
    "\n",
    "# Initialize the QiCNN network\n",
    "network = GlobalQNN(config_dict=qicnn_config)\n",
    "\n",
    "num_points = 513\n",
    "density = jnp.linspace(0, 1, num_points)\n",
    "init_fn, apply_fn = network.build_network(grids=density)\n",
    "\n",
    "# Initialize parameters and run inference\n",
    "rng_key = qicnn_config['key']\n",
    "_, params = init_fn(rng_key, input_shape=(-1, num_points, 1))\n",
    "output = apply_fn(params, density)\n",
    "\n",
    "# Print the output\n",
    "print(output)\n",
    "\n",
    "# # Initialize trainer\n",
    "# trainer = KSDFTTrainer(\n",
    "#     config_dict=config,\n",
    "#     network=network,\n",
    "#     data_path=project_path / 'data' / 'od'\n",
    "# )\n",
    "\n",
    "# # Train model\n",
    "# params, loss, info = trainer.train(\n",
    "#     checkpoint_save_dir=project_path / 'tests' / 'ckpts'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9d6f3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the Global QNN:  207\n"
     ]
    }
   ],
   "source": [
    "from qedft.models.utils import count_parameters\n",
    "print(\"Number of parameters in the Global QNN: \", count_parameters(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2e4459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(params[0]))\n",
    "print(len(params[1][0].flatten()))\n",
    "36 + 171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53402786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just quantum gates\n",
    "6 * 8 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f84a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:09:56.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:09:56.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:09:56.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:09:56.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing noise configurations ===\n",
      "\\n--- Noise scale: 0.0 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.0), 'phase_damping': np.float64(0.0), 'readout_error': 0.0}\n",
      "No noise applied (baseline)\n",
      "\\n--- Noise scale: 0.1 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.008040734235208813), 'phase_damping': np.float64(0.008911450699779777), 'readout_error': 0.021215800000000003}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n",
      "Output with noise (scale 0.1): [-8.08464626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:05.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:05.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:05.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:05.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with Gaussian noise: [-8.08503814]\n",
      "\\n--- Noise scale: 0.5 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.040203671176044065), 'phase_damping': np.float64(0.044557253498898886), 'readout_error': 0.106079}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:10.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:10.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:10.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:10.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with noise (scale 0.5): [-8.73678039]\n",
      "Output with Gaussian noise: [-8.73873979]\n",
      "\\n--- Noise scale: 1.0 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.08040734235208813), 'phase_damping': np.float64(0.08911450699779777), 'readout_error': 0.212158}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:16.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:16.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:16.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:16.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with noise (scale 1.0): [-9.49175595]\n",
      "Output with Gaussian noise: [-9.49567476]\n",
      "\\n--- Noise scale: 2.0 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.16081468470417626), 'phase_damping': np.float64(0.17822901399559554), 'readout_error': 0.424316}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:22.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:22.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:22.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:22.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with noise (scale 2.0): [-9.05171062]\n",
      "Output with Gaussian noise: [-9.05954823]\n",
      "\\n--- Noise scale: 5.0 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.40203671176044065), 'phase_damping': np.float64(0.44557253498898886), 'readout_error': 1.0}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n",
      "Output with noise (scale 5.0): [-10.54928486]\n",
      "Output with Gaussian noise: [-10.56775604]\n",
      "\\n=== Noise testing completed ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from horqrux.noise import DigitalNoiseInstance, DigitalNoiseType\n",
    "\n",
    "def calculate_noise_probabilities(t1_ns, t2_ns, gate_time_ns, readout_error):\n",
    "    \"\"\"\n",
    "    Calculate realistic noise probabilities from IBM device parameters.\n",
    "    \"\"\"\n",
    "    # Calculate amplitude damping probability: P = 1 - exp(-t_gate/T1)\n",
    "    amplitude_damping_prob = 1.0 - np.exp(-gate_time_ns / t1_ns)\n",
    "\n",
    "    # Calculate phase damping probability: P = 1 - exp(-t_gate/T2)\n",
    "    phase_damping_prob = 1.0 - np.exp(-gate_time_ns / t2_ns)\n",
    "\n",
    "    print(\"\\\\n===========================================\")\n",
    "    print(\"Summary of noise probabilities:\")\n",
    "    print(f\"T1: {t1_ns} ns, T2: {t2_ns} ns, Gate time: {gate_time_ns} ns\")\n",
    "    print(f\"Amplitude damping probability: {amplitude_damping_prob}\")\n",
    "    print(f\"Phase damping probability: {phase_damping_prob}\")\n",
    "    print(f\"Readout error: {readout_error}\")\n",
    "\n",
    "    return {\n",
    "        \"amplitude_damping\": amplitude_damping_prob,\n",
    "        \"phase_damping\": phase_damping_prob,\n",
    "        \"readout_error\": readout_error,\n",
    "    }\n",
    "\n",
    "def create_realistic_noise_config(noise_scale=1.0, device_type=\"best\"):\n",
    "    \"\"\"\n",
    "    Creates realistic noise configuration based on IBM device parameters.\n",
    "    \"\"\"\n",
    "    # IBM device parameters from the script\n",
    "    device_params = {\n",
    "        \"best\": {\n",
    "            \"t1_ns\": 593.86,\n",
    "            \"t2_ns\": 533.33,\n",
    "            \"gate_time_ns\": 49.78,\n",
    "            \"readout_error\": 0.212158,\n",
    "        },\n",
    "        \"worst\": {\n",
    "            \"t1_ns\": 433.44,\n",
    "            \"t2_ns\": 403.38,\n",
    "            \"gate_time_ns\": 60.00,\n",
    "            \"readout_error\": 0.504395,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    params = device_params[device_type]\n",
    "    noise_probs = calculate_noise_probabilities(**params)\n",
    "\n",
    "    # Scale noise probabilities\n",
    "    scaled_probs = {\n",
    "        key: min(prob * noise_scale, 1.0)  # Cap at 1.0\n",
    "        for key, prob in noise_probs.items()\n",
    "    }\n",
    "\n",
    "    print(f\"Scaled noise probabilities: {scaled_probs}\")\n",
    "\n",
    "    # Create noise instances for quantum gates\n",
    "    quantum_noise = (\n",
    "        DigitalNoiseInstance(\n",
    "            DigitalNoiseType.AMPLITUDE_DAMPING,\n",
    "            scaled_probs[\"amplitude_damping\"]\n",
    "        ),\n",
    "        DigitalNoiseInstance(\n",
    "            DigitalNoiseType.PHASE_DAMPING,\n",
    "            scaled_probs[\"phase_damping\"]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Add measurement/sampling noise as Gaussian noise\n",
    "    gaussian_noise_std = scaled_probs[\"readout_error\"] * 0.1\n",
    "\n",
    "    return {\n",
    "        \"noise\": quantum_noise,\n",
    "        \"add_gaussian_noise_to_qnn_output\": True,\n",
    "        \"gaussian_noise_std\": gaussian_noise_std,\n",
    "        \"scaled_probs\": scaled_probs\n",
    "    }\n",
    "\n",
    "# Test noise configuration with different scales\n",
    "noise_scales = [0.0, 0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "print(\"=== Testing noise configurations ===\")\n",
    "for scale in noise_scales:\n",
    "    print(f\"\\\\n--- Noise scale: {scale} ---\")\n",
    "    noise_config = create_realistic_noise_config(scale, \"best\")\n",
    "\n",
    "    if scale > 0.0:\n",
    "        # Create network with noise\n",
    "        network_with_noise = GlobalQNN(config_dict=qicnn_config)\n",
    "        init_fn_noisy, apply_fn_noisy = network_with_noise.build_network(\n",
    "            grids=density,\n",
    "            noise=noise_config[\"noise\"]\n",
    "        )\n",
    "\n",
    "        # Test inference with noise\n",
    "        _, params_noisy = init_fn_noisy(rng_key, input_shape=(-1, num_points, 1))\n",
    "        output_noisy = apply_fn_noisy(params_noisy, density)\n",
    "\n",
    "        print(f\"Output with noise (scale {scale}): {output_noisy}\")\n",
    "\n",
    "        # Add Gaussian noise to output if specified\n",
    "        if noise_config[\"add_gaussian_noise_to_qnn_output\"]:\n",
    "            noise_key = jax.random.PRNGKey(42)\n",
    "            gaussian_noise = jax.random.normal(\n",
    "                noise_key,\n",
    "                shape=output_noisy.shape\n",
    "            ) * noise_config[\"gaussian_noise_std\"]\n",
    "            output_with_gaussian = output_noisy + gaussian_noise\n",
    "            print(f\"Output with Gaussian noise: {output_with_gaussian}\")\n",
    "    else:\n",
    "        print(\"No noise applied (baseline)\")\n",
    "\n",
    "print(\"\\\\n=== Noise testing completed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be38dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:28.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:28.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:28.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:28.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Noise scale: 10 ---\n",
      "\\n===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.8040734235208813), 'phase_damping': np.float64(0.8911450699779777), 'readout_error': 1.0}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:34.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mInitialized trainer with config: {'name': 'test', 'experiment_name': 'test', 'network_type': 'conv_dqc', 'molecule_name': 'h2', 'molecule_names': ['h2'], 'dataset1': [128, 384], 'rng': 0, 'save_plot_loss': False, 'save_every_n': 20, 'activation': 'tanh', 'n_neurons': 513, 'n_layers': 2, 'n_qubits': 9, 'n_reupload_layers': 1, 'use_rzz_parametrized_entanglers': False, 'chebychev_reuploading': False, 'add_reversed_rzz': False, 'entangling_block_type': 'alternate_linear', 'single_qubit_rotations': ['rz', 'rx', 'rz'], 'use_same_parameters': False, 'add_negative_transform': False, 'wrap_with_self_interaction_layer': False, 'wrap_with_global_functional': False, 'use_correlators_in_output': False, 'output_operators': ['Z'], 'use_bias_in_output': False, 'max_train_steps': 10000, 'factr': 1.0, 'pgtol': 1e-14, 'm': 20, 'maxfun': 20, 'maxiter': 2, 'num_iterations': 15, 'ks_iter_to_ignore': 10, 'discount_factor': 0.9, 'alpha': 0.5, 'alpha_decay': 0.9, 'num_mixing_iterations': 1, 'density_mse_converge_tolerance': -1.0, 'stop_gradient_step': -1, 'enforce_reflection_symmetry': False, 'use_relative_encoding': False, 'num_grids': 513, 'use_amplitude_encoding': True, 'max_number_conv_layers': 100, 'list_qubits_per_layer': [], 'force_qubits_per_layer_is_kernel_width': False, 'feature_map_type': 'direct', 'final_mlp_layers': [1], 'dont_use_parametrized_observables': True, 'use_nel_as_input_with_mlp': False, 'nel_exc_combination_type': 'sum', 'nel_mlp_layers': [1], 'density_normalization_factor': 2.0, 'use_pmap_for_gpu_per_molecule': False, 'num_global_filters': 16, 'num_local_filters': 16, 'num_local_conv_layers': 2, 'ksr_activation': 'swish', 'ksr_minval': 0.1, 'ksr_maxval': 2.385345, 'ksr_downsample_factor': 0, 'use_exponential_coulomb': True, 'jit_loss': True, 'jit_neural_xc': True}\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:34.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mLoading dataset for h2\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:34.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mLoading dataset from /home/isokolov/qex/data/od/h2\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:34.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mTraining distances: [128, 384]\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:34.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mNumber of electrons: 2\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:34.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mGrid shape: (513,)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with noise (scale 10): [-13.41383076]\n",
      "Output with Gaussian noise: [-13.43230193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:35.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m268\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.wrappers\u001b[0m:\u001b[36mwrap_network\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mGlobal model, ensuring output is scalar (wrap_self_interaction causes global models to output (num_grids,) instead of (1,))\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mInitializing fresh parameters\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mJitting neural_xc_energy_density_fn\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-24 18:10:35.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mJitting loss_fn\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mCheckpoint save directory: /home/isokolov/qex/tests/ckpts\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mOptimizing with L-BFGS-B: {'maxfun': 20, 'factr': 1.0, 'm': 20, 'pgtol': 1e-14, 'maxiter': 2}\u001b[0m\n",
      "\u001b[32m2025-07-24 18:10:35.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36m_kohn_sham\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mJitting kohn_sham_func\u001b[0m\n",
      "\u001b[32m2025-07-24 18:16:16.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36mnp_value_and_grad_fn\u001b[0m:\u001b[36m454\u001b[0m - \u001b[1mstep 0, loss 0.4996592183852752 in 340.3263998031616 sec\u001b[0m\n",
      "\u001b[32m2025-07-24 18:16:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36mnp_value_and_grad_fn\u001b[0m:\u001b[36m458\u001b[0m - \u001b[1mSave checkpoint /home/isokolov/qex/tests/ckpts/ckpt-00000\u001b[0m\n",
      "\u001b[32m2025-07-24 18:16:18.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36mnp_value_and_grad_fn\u001b[0m:\u001b[36m454\u001b[0m - \u001b[1mstep 1, loss 54.41394066219689 in 2.040738821029663 sec\u001b[0m\n",
      "\u001b[32m2025-07-24 18:16:20.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36mnp_value_and_grad_fn\u001b[0m:\u001b[36m454\u001b[0m - \u001b[1mstep 2, loss 0.020128774379635582 in 2.0418152809143066 sec\u001b[0m\n",
      "\u001b[32m2025-07-24 18:16:22.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36mnp_value_and_grad_fn\u001b[0m:\u001b[36m454\u001b[0m - \u001b[1mstep 3, loss 0.020061611376961767 in 2.041247844696045 sec\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Noise scale\n",
    "scale = 10\n",
    "\n",
    "print(f\"\\\\n--- Noise scale: {scale} ---\")\n",
    "noise_config = create_realistic_noise_config(scale, \"best\")\n",
    "\n",
    "if scale > 0.0:\n",
    "    # Create network with noise\n",
    "    network_with_noise = GlobalQNN(config_dict=qicnn_config)\n",
    "    init_fn_noisy, apply_fn_noisy = network_with_noise.build_network(\n",
    "        grids=density,\n",
    "        noise=noise_config[\"noise\"]\n",
    "    )\n",
    "\n",
    "    # Test inference with noise\n",
    "    _, params_noisy = init_fn_noisy(rng_key, input_shape=(-1, num_points, 1))\n",
    "    output_noisy = apply_fn_noisy(params_noisy, density)\n",
    "\n",
    "    print(f\"Output with noise (scale {scale}): {output_noisy}\")\n",
    "\n",
    "    # Add Gaussian noise to output if specified\n",
    "    if noise_config[\"add_gaussian_noise_to_qnn_output\"]:\n",
    "        noise_key = jax.random.PRNGKey(42)\n",
    "        gaussian_noise = jax.random.normal(\n",
    "            noise_key,\n",
    "            shape=output_noisy.shape\n",
    "        ) * noise_config[\"gaussian_noise_std\"]\n",
    "        output_with_gaussian = output_noisy + gaussian_noise\n",
    "        print(f\"Output with Gaussian noise: {output_with_gaussian}\")\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = KSDFTTrainer(\n",
    "        config_dict=config,\n",
    "        network=network,\n",
    "        data_path=project_path / 'data' / 'od'\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    params, loss, info = trainer.train(\n",
    "        checkpoint_save_dir=project_path / 'tests' / 'ckpts'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b413426c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# We have that it takes 340.3263998031616 sec to compile the loss function\n",
    "\n",
    "2025-07-24 18:10:35.951 | INFO     | qedft.train.od.trainer:train:140 - Jitting loss_fn\n",
    "2025-07-24 18:10:35.953 | INFO     | qedft.train.od.trainer:train:151 - Checkpoint save directory: /home/isokolov/qex/tests/ckpts\n",
    "2025-07-24 18:10:35.953 | INFO     | qedft.train.od.trainer:train:173 - Optimizing with L-BFGS-B: {'maxfun': 20, 'factr': 1.0, 'm': 20, 'pgtol': 1e-14, 'maxiter': 2}\n",
    "2025-07-24 18:10:35.960 | INFO     | qedft.train.od.train:_kohn_sham:116 - Jitting kohn_sham_func\n",
    "2025-07-24 18:16:16.302 | INFO     | qedft.train.od.train:np_value_and_grad_fn:454 - step 0, loss 0.4996592183852752 in 340.3263998031616 sec"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9200a59",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
