{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574f0909",
   "metadata": {},
   "source": [
    "# Compile time for GlobalQNN with and without gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb95cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ax (/home/isokolov/qex/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mjax                      0.6.2\n",
      "jax-cuda12-pjrt          0.6.2\n",
      "jax-cuda12-plugin        0.6.2\n",
      "jax-dft                  0.0.0\n",
      "jaxlib                   0.6.2\n",
      "jaxopt                   0.8.5\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ax (/home/isokolov/qex/.venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mhorqrux                  0.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep jax\n",
    "!pip list | grep horqrux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fbf2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 00:59:10.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:10.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 00:59:10.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:10.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1mAdding gaussian noise to the output of QNN with std 0.5\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:10.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.04025798]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import qedft\n",
    "from qedft.models.networks import GlobalQiCQNN, GlobalQiQNN, GlobalQNN\n",
    "from qedft.config.config import Config\n",
    "from qedft.train.od.trainer import KSDFTTrainer\n",
    "from horqrux.utils.operator_utils import DiffMode\n",
    "from loguru import logger\n",
    "\n",
    "# Set the default dtype as float64\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "# set gpu device\n",
    "jax.config.update(\"jax_platform_name\", \"cuda\")  # \"cuda\" or \"cpu\"\n",
    "\n",
    "# Get project path\n",
    "project_path = Path(os.path.dirname(os.path.dirname(qedft.__file__)))\n",
    "\n",
    "# Load base configuration\n",
    "config = Config(config_path=project_path / 'qedft' / 'config' / 'train_config.yaml').config\n",
    "\n",
    "# Let's change to settings to have a global functional\n",
    "config['network_type'] = 'conv_dqc'\n",
    "config['use_amplitude_encoding'] = True\n",
    "\n",
    "# Configure GlobalQNN\n",
    "qicnn_config = {\n",
    "    \"network_type\": \"conv_dqc\",\n",
    "    \"wrap_self_interaction\": False,\n",
    "    \"wrap_with_negative_transform\": False,\n",
    "    \"use_amplitude_encoding\": False,\n",
    "    \"n_qubits\": 6,  # Number of qubits in the quantum layer\n",
    "    \"n_var_layers\": 8,  # Number of quantum layers\n",
    "    \"n_layers\": 8,\n",
    "    \"largest_kernel_width\": 3,\n",
    "    \"max_number_conv_layers\": 1,  # Limit to 1 convolutional layer\n",
    "    \"list_qubits_per_layer\": [],\n",
    "    \"force_qubits_per_layer_is_kernel_width\": False,\n",
    "    \"normalization\": 1.0,\n",
    "    \"last_layer_type\": \"dense\",  # Use a linear layer at the end\n",
    "    \"use_bias_mlp\": False,\n",
    "    \"last_layer_features\": [1],\n",
    "    \"diff_mode\": DiffMode.AD,\n",
    "    \"n_shots\": 0,\n",
    "    \"key\": jax.random.PRNGKey(0)\n",
    "}\n",
    "\n",
    "# Initialize the\n",
    "#\n",
    "#\n",
    "#  network\n",
    "network = GlobalQNN(config_dict=qicnn_config)\n",
    "\n",
    "num_points = 513\n",
    "density = jnp.linspace(0, 1, num_points)\n",
    "init_fn, apply_fn = network.build_network(grids=density)\n",
    "\n",
    "# Initialize parameters and run inference\n",
    "rng_key = qicnn_config['key']\n",
    "_, params = init_fn(rng_key, input_shape=(-1, num_points, 1))\n",
    "output = apply_fn(params, density)\n",
    "\n",
    "# Print the output\n",
    "print(output)\n",
    "\n",
    "# # Initialize trainer\n",
    "# trainer = KSDFTTrainer(\n",
    "#     config_dict=config,\n",
    "#     network=network,\n",
    "#     data_path=project_path / 'data' / 'od'\n",
    "# )\n",
    "\n",
    "# # Train model\n",
    "# params, loss, info = trainer.train(\n",
    "#     checkpoint_save_dir=project_path / 'tests' / 'ckpts'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6f3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the Global QNN:  315\n"
     ]
    }
   ],
   "source": [
    "from qedft.models.utils import count_parameters\n",
    "print(\"Number of parameters in the Global QNN: \", count_parameters(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e4459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(params[0]))\n",
    "print(len(params[1][0].flatten()))\n",
    "# With 2 layers\n",
    "36 + 171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53402786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just quantum gates\n",
    "6 * 8 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f84a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 00:59:26.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:26.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:26.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:26.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1mAdding gaussian noise to the output of QNN with std 0.5\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:26.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing noise configurations ===\n",
      "\\n--- Noise scale: 5.0 ---\n",
      "\n",
      "===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.40203671176044065), 'phase_damping': np.float64(0.44557253498898886), 'readout_error': 1.0}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n",
      "Output with noise (scale 5.0): [-11.91680463]\n",
      "Output with Gaussian noise: [-11.93527581]\n",
      "\\n=== Noise testing completed ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from horqrux.noise import DigitalNoiseInstance, DigitalNoiseType\n",
    "\n",
    "def calculate_noise_probabilities(t1_ns, t2_ns, gate_time_ns, readout_error):\n",
    "    \"\"\"\n",
    "    Calculate realistic noise probabilities from IBM device parameters.\n",
    "    \"\"\"\n",
    "    # Calculate amplitude damping probability: P = 1 - exp(-t_gate/T1)\n",
    "    amplitude_damping_prob = 1.0 - np.exp(-gate_time_ns / t1_ns)\n",
    "\n",
    "    # Calculate phase damping probability: P = 1 - exp(-t_gate/T2)\n",
    "    phase_damping_prob = 1.0 - np.exp(-gate_time_ns / t2_ns)\n",
    "\n",
    "    print(\"\\n===========================================\")\n",
    "    print(\"Summary of noise probabilities:\")\n",
    "    print(f\"T1: {t1_ns} ns, T2: {t2_ns} ns, Gate time: {gate_time_ns} ns\")\n",
    "    print(f\"Amplitude damping probability: {amplitude_damping_prob}\")\n",
    "    print(f\"Phase damping probability: {phase_damping_prob}\")\n",
    "    print(f\"Readout error: {readout_error}\")\n",
    "\n",
    "    return {\n",
    "        \"amplitude_damping\": amplitude_damping_prob,\n",
    "        \"phase_damping\": phase_damping_prob,\n",
    "        \"readout_error\": readout_error,\n",
    "    }\n",
    "\n",
    "def create_realistic_noise_config(noise_scale=1.0, device_type=\"best\"):\n",
    "    \"\"\"\n",
    "    Creates realistic noise configuration based on IBM device parameters.\n",
    "    \"\"\"\n",
    "    # IBM device parameters from the script\n",
    "    device_params = {\n",
    "        \"best\": {\n",
    "            \"t1_ns\": 593.86,\n",
    "            \"t2_ns\": 533.33,\n",
    "            \"gate_time_ns\": 49.78,\n",
    "            \"readout_error\": 0.212158,\n",
    "        },\n",
    "        \"worst\": {\n",
    "            \"t1_ns\": 433.44,\n",
    "            \"t2_ns\": 403.38,\n",
    "            \"gate_time_ns\": 60.00,\n",
    "            \"readout_error\": 0.504395,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    params = device_params[device_type]\n",
    "    noise_probs = calculate_noise_probabilities(**params)\n",
    "\n",
    "    # Scale noise probabilities\n",
    "    scaled_probs = {\n",
    "        key: min(prob * noise_scale, 1.0)  # Cap at 1.0\n",
    "        for key, prob in noise_probs.items()\n",
    "    }\n",
    "\n",
    "    print(f\"Scaled noise probabilities: {scaled_probs}\")\n",
    "\n",
    "    # Create noise instances for quantum gates\n",
    "    quantum_noise = (\n",
    "        DigitalNoiseInstance(\n",
    "            DigitalNoiseType.AMPLITUDE_DAMPING,\n",
    "            scaled_probs[\"amplitude_damping\"]\n",
    "        ),\n",
    "        DigitalNoiseInstance(\n",
    "            DigitalNoiseType.PHASE_DAMPING,\n",
    "            scaled_probs[\"phase_damping\"]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Add measurement/sampling noise as Gaussian noise\n",
    "    gaussian_noise_std = scaled_probs[\"readout_error\"] * 0.1\n",
    "\n",
    "    return {\n",
    "        \"noise\": quantum_noise,\n",
    "        \"add_gaussian_noise_to_qnn_output\": True,\n",
    "        \"gaussian_noise_std\": gaussian_noise_std,\n",
    "        \"scaled_probs\": scaled_probs\n",
    "    }\n",
    "\n",
    "# Test noise configuration with different scales\n",
    "# noise_scales = [0.0, 0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "noise_scales = [5.0]\n",
    "\n",
    "print(\"=== Testing noise configurations ===\")\n",
    "for scale in noise_scales:\n",
    "    print(f\"\\\\n--- Noise scale: {scale} ---\")\n",
    "    noise_config = create_realistic_noise_config(scale, \"best\")\n",
    "\n",
    "    if scale > 0.0:\n",
    "        # Create network with noise\n",
    "        network_with_noise = GlobalQNN(config_dict=qicnn_config)\n",
    "        init_fn_noisy, apply_fn_noisy = network_with_noise.build_network(\n",
    "            grids=density,\n",
    "            noise=noise_config[\"noise\"]\n",
    "        )\n",
    "\n",
    "        # Test inference with noise\n",
    "        _, params_noisy = init_fn_noisy(rng_key, input_shape=(-1, num_points, 1))\n",
    "        # No jit\n",
    "        output_noisy = apply_fn_noisy(params_noisy, density)\n",
    "\n",
    "        print(f\"Output with noise (scale {scale}): {output_noisy}\")\n",
    "\n",
    "        # Add Gaussian noise to output if specified\n",
    "        if noise_config[\"add_gaussian_noise_to_qnn_output\"]:\n",
    "            noise_key = jax.random.PRNGKey(42)\n",
    "            gaussian_noise = jax.random.normal(\n",
    "                noise_key,\n",
    "                shape=output_noisy.shape\n",
    "            ) * noise_config[\"gaussian_noise_std\"]\n",
    "            output_with_gaussian = output_noisy + gaussian_noise\n",
    "            print(f\"Output with Gaussian noise: {output_with_gaussian}\")\n",
    "    else:\n",
    "        print(\"No noise applied (baseline)\")\n",
    "\n",
    "print(\"\\\\n=== Noise testing completed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb9316",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from qedft.models.networks import KohnShamNetwork\n",
    "from qedft.models.quantum.simple_gqnn import build_simple_qnn_with_linear\n",
    "\n",
    "class SimpleGlobalQNN(KohnShamNetwork):\n",
    "    \"\"\"Simple Global Quantum Neural Network using build_simple_qnn_with_linear.\"\"\"\n",
    "\n",
    "    def __init__(self, config_dict: dict | None = None):\n",
    "        \"\"\"Initialize from config dictionary.\"\"\"\n",
    "        super().__init__(config_dict)\n",
    "        self.config = {\n",
    "            \"network_type\": \"mlp_ksr\",\n",
    "            \"wrap_self_interaction\": False,\n",
    "            \"wrap_with_negative_transform\": True,\n",
    "            \"use_amplitude_encoding\": True,\n",
    "            \"n_qubits\": 4,\n",
    "            \"n_layers\": 2,\n",
    "            \"num_batches\": 171,\n",
    "            \"num_features\": 3,\n",
    "            \"feature_type\": \"direct\",\n",
    "            \"add_gaussian_noise_to_qnn_output\": False,\n",
    "            \"gaussian_noise_std\": 0.001,\n",
    "        }\n",
    "        if config_dict is not None:\n",
    "            self.config.update(config_dict)\n",
    "\n",
    "    def build_network(\n",
    "        self,\n",
    "        grids: jnp.ndarray,\n",
    "        noise: None = None,\n",
    "    ) -> tuple:\n",
    "        \"\"\"Build the simple global QNN using build_simple_qnn_with_linear.\n",
    "\n",
    "        Args:\n",
    "            grids: Grid points for the density functional calculations.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (init_fn, apply_fn) pair of network initialization and application functions.\n",
    "        \"\"\"\n",
    "        # Determine num_batches and num_features from grids if not set\n",
    "        num_points = grids.shape[0]\n",
    "        num_features = self.config.get(\"num_features\", 3)\n",
    "        num_batches = self.config.get(\"num_batches\", num_points // num_features)\n",
    "\n",
    "        network = build_simple_qnn_with_linear(\n",
    "            n_qubits=self.config.get(\"n_qubits\", 4),\n",
    "            num_batches=num_batches,\n",
    "            num_features=num_features,\n",
    "            n_layers=self.config.get(\"n_layers\", 2),\n",
    "            feature_type=self.config.get(\"feature_type\", \"direct\"),\n",
    "            add_gaussian_noise_to_qnn_output=self.config.get(\"add_gaussian_noise_to_qnn_output\", False),\n",
    "            noise_std=self.config.get(\"gaussian_noise_std\", 0.001),\n",
    "            gate_noise=noise,\n",
    "        )\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c91af36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 00:59:52.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.wrappers\u001b[0m:\u001b[36mwrap_network\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mGlobal model, ensuring output is scalar (wrap_self_interaction causes global models to output (num_grids,) instead of (1,))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Noise scale: 1.0 ---\n",
      "\n",
      "===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.08040734235208813), 'phase_damping': np.float64(0.08911450699779777), 'readout_error': 0.212158}\n",
      "=== Testing Neural XC Functional ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 00:59:57.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mInitialized trainer with config: {'name': 'test', 'experiment_name': 'test', 'network_type': 'conv_dqc', 'molecule_name': 'h2', 'molecule_names': ['h2'], 'dataset1': [128, 384], 'rng': 0, 'save_plot_loss': False, 'save_every_n': 20, 'activation': 'tanh', 'n_neurons': 513, 'n_layers': 2, 'n_qubits': 9, 'n_reupload_layers': 1, 'use_rzz_parametrized_entanglers': False, 'chebychev_reuploading': False, 'add_reversed_rzz': False, 'entangling_block_type': 'alternate_linear', 'single_qubit_rotations': ['rz', 'rx', 'rz'], 'use_same_parameters': False, 'add_negative_transform': False, 'wrap_with_self_interaction_layer': False, 'wrap_with_global_functional': False, 'use_correlators_in_output': False, 'output_operators': ['Z'], 'use_bias_in_output': False, 'max_train_steps': 10000, 'factr': 1.0, 'pgtol': 1e-14, 'm': 20, 'maxfun': 10000, 'maxiter': 10000, 'num_iterations': 15, 'ks_iter_to_ignore': 10, 'discount_factor': 0.9, 'alpha': 0.5, 'alpha_decay': 0.9, 'num_mixing_iterations': 1, 'density_mse_converge_tolerance': -1.0, 'stop_gradient_step': -1, 'enforce_reflection_symmetry': False, 'use_relative_encoding': False, 'num_grids': 513, 'use_amplitude_encoding': True, 'max_number_conv_layers': 100, 'list_qubits_per_layer': [], 'force_qubits_per_layer_is_kernel_width': False, 'feature_map_type': 'direct', 'final_mlp_layers': [1], 'dont_use_parametrized_observables': True, 'use_nel_as_input_with_mlp': False, 'nel_exc_combination_type': 'sum', 'nel_mlp_layers': [1], 'density_normalization_factor': 2.0, 'use_pmap_for_gpu_per_molecule': False, 'num_global_filters': 16, 'num_local_filters': 16, 'num_local_conv_layers': 2, 'ksr_activation': 'swish', 'ksr_minval': 0.1, 'ksr_maxval': 2.385345, 'ksr_downsample_factor': 0, 'use_exponential_coulomb': True, 'jit_loss': True, 'jit_neural_xc': True}\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:57.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mLoading dataset for h2\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:57.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mLoading dataset from /home/isokolov/qex/data/od/h2\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:57.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mTraining distances: [128, 384]\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:57.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mNumber of electrons: 2\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:57.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mGrid shape: (513,)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (scalar): 4.177025485686976\n",
      "Result shape: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-06 00:59:58.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.wrappers\u001b[0m:\u001b[36mwrap_network\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mGlobal model, ensuring output is scalar (wrap_self_interaction causes global models to output (num_grids,) instead of (1,))\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:58.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mInitializing fresh parameters\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:58.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mJitting neural_xc_energy_density_fn\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:58.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mJitting loss_fn\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:58.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mCheckpoint save directory: /home/isokolov/qex/tests/ckpts\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:58.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mOptimizing with L-BFGS-B: {'maxfun': 10000, 'factr': 1.0, 'm': 20, 'pgtol': 1e-14, 'maxiter': 10000}\u001b[0m\n",
      "\u001b[32m2025-08-06 00:59:58.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36m_kohn_sham\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mJitting kohn_sham_func\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from qedft.models.quantum.simple_gqnn import build_simple_qnn_with_linear\n",
    "\n",
    "# Noise scale\n",
    "scale = 1.0\n",
    "\n",
    "qicnn_config = {\n",
    "    \"network_type\": \"mlp_ksr\",\n",
    "    \"use_amplitude_encoding\": True,\n",
    "    \"n_qubits\": 6,\n",
    "    \"n_layers\": 8,\n",
    "    \"num_batches\": 171,\n",
    "    \"num_features\": 3,\n",
    "    \"feature_type\": \"direct\",\n",
    "    \"add_gaussian_noise_to_qnn_output\": False,\n",
    "    \"gaussian_noise_std\": 0.001,\n",
    "}\n",
    "\n",
    "print(f\"\\\\n--- Noise scale: {scale} ---\")\n",
    "noise_config = create_realistic_noise_config(scale, \"best\")\n",
    "\n",
    "if scale > 0.0:\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    init_fn_noisy, apply_fn_noisy = build_simple_qnn_with_linear(n_qubits=qicnn_config['n_qubits'], num_batches=513//3, num_features=3, n_layers=8, feature_type=\"direct\", add_gaussian_noise_to_qnn_output=True, noise_std=0.001)\n",
    "\n",
    "    print(\"=== Testing Neural XC Functional ===\")\n",
    "    from qedft.models.wrappers import wrap_network\n",
    "    x = jnp.ones((513,))\n",
    "    init_fn, apply_fn = wrap_network((init_fn_noisy, apply_fn_noisy), x, \"mlp_ksr\", wrap_self_interaction=False, wrap_with_negative_transform=False)\n",
    "    params = init_fn(key)\n",
    "    result = apply_fn(x, params)\n",
    "    print(f\"Result (scalar): {result}\")\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "\n",
    "    network = SimpleGlobalQNN(config_dict=qicnn_config)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = KSDFTTrainer(\n",
    "        config_dict=config,\n",
    "        network=network,\n",
    "        data_path=project_path / 'data' / 'od'\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    params, loss, info = trainer.train(\n",
    "        checkpoint_save_dir=project_path / 'tests' / 'ckpts'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be38dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-04 15:25:35.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:35.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:35.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:35.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1mAdding gaussian noise to the output of QNN with std 0.5\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:35.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Noise scale: 1.0 ---\n",
      "\n",
      "===========================================\n",
      "Summary of noise probabilities:\n",
      "T1: 593.86 ns, T2: 533.33 ns, Gate time: 49.78 ns\n",
      "Amplitude damping probability: 0.08040734235208813\n",
      "Phase damping probability: 0.08911450699779777\n",
      "Readout error: 0.212158\n",
      "Scaled noise probabilities: {'amplitude_damping': np.float64(0.08040734235208813), 'phase_damping': np.float64(0.08911450699779777), 'readout_error': 0.212158}\n",
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-04 15:25:58.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mInitialized trainer with config: {'name': 'test', 'experiment_name': 'test', 'network_type': 'conv_dqc', 'molecule_name': 'h2', 'molecule_names': ['h2'], 'dataset1': [128, 384], 'rng': 0, 'save_plot_loss': False, 'save_every_n': 20, 'activation': 'tanh', 'n_neurons': 513, 'n_layers': 2, 'n_qubits': 9, 'n_reupload_layers': 1, 'use_rzz_parametrized_entanglers': False, 'chebychev_reuploading': False, 'add_reversed_rzz': False, 'entangling_block_type': 'alternate_linear', 'single_qubit_rotations': ['rz', 'rx', 'rz'], 'use_same_parameters': False, 'add_negative_transform': False, 'wrap_with_self_interaction_layer': False, 'wrap_with_global_functional': False, 'use_correlators_in_output': False, 'output_operators': ['Z'], 'use_bias_in_output': False, 'max_train_steps': 10000, 'factr': 1.0, 'pgtol': 1e-14, 'm': 20, 'maxfun': 10000, 'maxiter': 10000, 'num_iterations': 15, 'ks_iter_to_ignore': 10, 'discount_factor': 0.9, 'alpha': 0.5, 'alpha_decay': 0.9, 'num_mixing_iterations': 1, 'density_mse_converge_tolerance': -1.0, 'stop_gradient_step': -1, 'enforce_reflection_symmetry': False, 'use_relative_encoding': False, 'num_grids': 513, 'use_amplitude_encoding': True, 'max_number_conv_layers': 100, 'list_qubits_per_layer': [], 'force_qubits_per_layer_is_kernel_width': False, 'feature_map_type': 'direct', 'final_mlp_layers': [1], 'dont_use_parametrized_observables': True, 'use_nel_as_input_with_mlp': False, 'nel_exc_combination_type': 'sum', 'nel_mlp_layers': [1], 'density_normalization_factor': 2.0, 'use_pmap_for_gpu_per_molecule': False, 'num_global_filters': 16, 'num_local_filters': 16, 'num_local_conv_layers': 2, 'ksr_activation': 'swish', 'ksr_minval': 0.1, 'ksr_maxval': 2.385345, 'ksr_downsample_factor': 0, 'use_exponential_coulomb': True, 'jit_loss': True, 'jit_neural_xc': True}\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:58.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mLoading dataset for h2\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:58.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mLoading dataset from /home/isokolov/qex/data/od/h2\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:58.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mTraining distances: [128, 384]\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:58.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mNumber of electrons: 2\u001b[0m\n",
      "\u001b[32m2025-08-04 15:25:58.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.data_io.dataset_loader\u001b[0m:\u001b[36mload_molecular_datasets\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mGrid shape: (513,)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with noise (scale 1.0): [-10.00914707]\n",
      "Output with Gaussian noise: [-10.01306588]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-04 15:26:00.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUsing GlobalQNNLayer layer\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mGlobalQNNLayer Layer 0: n_qubits_layer 6\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.quantum_models\u001b[0m:\u001b[36mbuild_qnn\u001b[0m:\u001b[36m683\u001b[0m - \u001b[1mBuilding GlobalQNN QNN with DirectQNN layer_type\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m246\u001b[0m - \u001b[1mAdding gaussian noise to the output of QNN with std 0.5\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.quantum.convolutional_models\u001b[0m:\u001b[36mconstruct_convolutional_model\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mAdding a single dense layer at the end (outputs last layer 171)\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.models.wrappers\u001b[0m:\u001b[36mwrap_network\u001b[0m:\u001b[36m205\u001b[0m - \u001b[1mGlobal model, ensuring output is scalar (wrap_self_interaction causes global models to output (num_grids,) instead of (1,))\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mInitializing fresh parameters\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mJitting neural_xc_energy_density_fn\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_kernel_dimensions , list_outputs_per_conv_layer:  [3] [171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-04 15:26:00.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mJitting loss_fn\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mCheckpoint save directory: /home/isokolov/qex/tests/ckpts\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mOptimizing with L-BFGS-B: {'maxfun': 10000, 'factr': 1.0, 'm': 20, 'pgtol': 1e-14, 'maxiter': 10000}\u001b[0m\n",
      "\u001b[32m2025-08-04 15:26:00.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mqedft.train.od.train\u001b[0m:\u001b[36m_kohn_sham\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mJitting kohn_sham_func\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Noise scale\n",
    "scale = 1.0\n",
    "\n",
    "print(f\"\\\\n--- Noise scale: {scale} ---\")\n",
    "noise_config = create_realistic_noise_config(scale, \"best\")\n",
    "\n",
    "if scale > 0.0:\n",
    "    # Create network with noise\n",
    "    network_with_noise = GlobalQNN(config_dict=qicnn_config)\n",
    "    init_fn_noisy, apply_fn_noisy = network_with_noise.build_network(\n",
    "        grids=density,\n",
    "        noise=noise_config[\"noise\"]\n",
    "    )\n",
    "\n",
    "    # Test inference with noise\n",
    "    _, params_noisy = init_fn_noisy(rng_key, input_shape=(-1, num_points, 1))\n",
    "    output_noisy = apply_fn_noisy(params_noisy, density)\n",
    "\n",
    "    print(f\"Output with noise (scale {scale}): {output_noisy}\")\n",
    "\n",
    "    # Add Gaussian noise to output if specified\n",
    "    if noise_config[\"add_gaussian_noise_to_qnn_output\"]:\n",
    "        noise_key = jax.random.PRNGKey(42)\n",
    "        gaussian_noise = jax.random.normal(\n",
    "            noise_key,\n",
    "            shape=output_noisy.shape\n",
    "        ) * noise_config[\"gaussian_noise_std\"]\n",
    "        output_with_gaussian = output_noisy + gaussian_noise\n",
    "        print(f\"Output with Gaussian noise: {output_with_gaussian}\")\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = KSDFTTrainer(\n",
    "        config_dict=config,\n",
    "        network=network,\n",
    "        data_path=project_path / 'data' / 'od'\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    params, loss, info = trainer.train(\n",
    "        checkpoint_save_dir=project_path / 'tests' / 'ckpts'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b413426c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# We have that it takes 340.3263998031616 sec to compile the loss function so 6min+\n",
    "\n",
    "2025-07-24 18:10:35.951 | INFO     | qedft.train.od.trainer:train:140 - Jitting loss_fn\n",
    "2025-07-24 18:10:35.953 | INFO     | qedft.train.od.trainer:train:151 - Checkpoint save directory: /home/isokolov/qex/tests/ckpts\n",
    "2025-07-24 18:10:35.953 | INFO     | qedft.train.od.trainer:train:173 - Optimizing with L-BFGS-B: {'maxfun': 20, 'factr': 1.0, 'm': 20, 'pgtol': 1e-14, 'maxiter': 2}\n",
    "2025-07-24 18:10:35.960 | INFO     | qedft.train.od.train:_kohn_sham:116 - Jitting kohn_sham_func\n",
    "2025-07-24 18:16:16.302 | INFO     | qedft.train.od.train:np_value_and_grad_fn:454 - step 0, loss 0.4996592183852752 in 340.3263998031616 sec"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9200a59",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "With more recent package of JAX, I have now:\n",
    "\n",
    "jax                      0.5.0\n",
    "jax-cuda12-pjrt          0.5.0\n",
    "jax-cuda12-plugin        0.5.0\n",
    "jax-dft                  0.0.0\n",
    "jaxlib                   0.5.0\n",
    "jaxopt                   0.8.5\n",
    "\n",
    "It all runs and compiles fast enough.\n",
    "They might have changed something on the compilation time, but I am not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df02ac",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Still I do not understand why the compilation time is so long when running from a script.\n",
    "I get like 6 min here but on the cluster like 1 hour and 12 sec per eval."
   ]
  },
  {
   "cell_type": "raw",
   "id": "55942c57",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
